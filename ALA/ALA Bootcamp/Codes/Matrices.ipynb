{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"BZLeh7V3Pfha"},"outputs":[],"source":["## Load Libraries\n","import pandas as pd\n","import numpy as np\n","import sympy as sp\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"dKsiLUXA5s3L"},"source":["---\n","\n","Dot product between two vectors is simply a pairwise-multiplication followed by a summation: for example, $a\\cdot b = a_1\\times b_2+a_2\\times b_2+\\cdots+a_n\\times b_n.$\n","\n","---"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"uydujPEZ5e5R"},"outputs":[{"data":{"text/plain":["32"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["a = np.array([1, 2, 3])\n","b = np.array([4, 5, 6])\n","np.dot(a, b)"]},{"cell_type":"markdown","metadata":{"id":"GyhODmJb594l"},"source":["---\n","\n","$L_2$ norm or the geometric length of a vector denoted as $\\lVert a\\rVert$ tells us how long a vector is. In 2-dimensions, $\\lVert a\\rVert_2 = \\sqrt{a_1^2+a_2^2}$ and in $n$-dimensions, $\\lVert a\\rVert_2 = \\sqrt{a_1^2+a_2^2+\\cdots+a_n^2}.$\n","\n","---"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"g0Pmt5oa6CTJ"},"outputs":[{"data":{"text/plain":["3.7416573867739413"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["np.linalg.norm(a)"]},{"cell_type":"markdown","metadata":{"id":"T0MIWP2p6NmF"},"source":["---\n","\n","Cauchy-Schwarz inequality $-1\\leq\\frac{a\\cdot b}{\\lVert a\\rVert\\lVert b\\rVert}\\leq1.$\n","\n","---"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"xejXi_-Y6d49"},"outputs":[{"data":{"text/plain":["0.9746318461970762"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["np.dot(a, b) / (np.linalg.norm(a)*np.linalg.norm(b))"]},{"cell_type":"markdown","metadata":{"id":"iQULPDF1Hayn"},"source":["---\n","\n","Matrix-vector product is simply a sequence of dot products of the rows of matrix (seen as vectors) with the vector\n","\n","---"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"eRPsIl-qHhO2"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[ 1  2 -1 -1]\n"," [ 2  4 -2  3]\n"," [-1  1 -2  4]]\n","(3, 4)\n","[ 1  2 -1 -1]\n","[ 2  4 -2  3]\n","[-1  1 -2  4]\n","(4,)\n","[-1  1  1  0]\n","[0 0 0]\n"]}],"source":["A = np.array([[1,2,-1,-1], [2,4,-2,3], [-1,1,-2,4]])\n","x = np.array([-1, 1, 1, 0])\n","print(A)\n","print(A.shape)\n","print(A[0])\n","print(A[1])\n","print(A[2])\n","print(A[0].shape)\n","print(x)\n","print(np.dot(A, x))"]},{"cell_type":"markdown","metadata":{"id":"Qh6HgpDaLVXD"},"source":["---\n","\n","A tensor of dimension 3 corresponding to 4 time stamps, 3 samples, 2 features (HR and BP)\n","\n","---"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"5SgAd6taLWsS"},"outputs":[{"name":"stdout","output_type":"stream","text":["(4, 3, 2)\n","[[[ 74 128]\n","  [ 79 116]\n","  [ 71 116]]\n","\n"," [[ 78 118]\n","  [ 82 124]\n","  [ 72 128]]\n","\n"," [[ 84 138]\n","  [ 84 130]\n","  [ 74 120]]\n","\n"," [[ 82 126]\n","  [ 76 156]\n","  [ 82 132]]]\n","[[ 74 128]\n"," [ 79 116]\n"," [ 71 116]]\n","[ 74 128]\n"]}],"source":["# Create a tensor of dimesion 3\n","# 4 time stamps, 3 paitent, 2 features\n","T = np.array([[[74, 128], [79, 116], [71, 116]],\n","              [[78, 118], [82, 124], [72, 128]],\n","              [[84, 138], [84, 130], [74, 120]],\n","              [[82, 126], [76, 156], [82, 132]]])\n","print(T.shape)\n","print(T)\n","print(T[0])\n","print(T[0][0])"]},{"cell_type":"markdown","metadata":{"id":"fw1G6_FaC086"},"source":["---\n","\n","Reshape tensor to represent (patient, feature, timestamps). That is, the timestamp becomes the last index.\n","\n","---"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"KTKxyxXjrj7P"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[ 74  78  84  82]\n","  [128 118 138 126]]\n","\n"," [[ 79  82  84  76]\n","  [116 124 130 156]]\n","\n"," [[ 71  72  74  82]\n","  [116 128 120 132]]]\n","[[ 74  78  84  82]\n"," [128 118 138 126]]\n","[[ 78 118]\n"," [ 82 124]\n"," [ 72 128]]\n"]}],"source":["T_reshaped = T.transpose(1, 2, 0)\n","print(T_reshaped)\n","print(T_reshaped[0])\n","print(T_reshaped[:, :, 1])"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"VmBBqj6qC5np"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[ 74  79  71]\n","  [ 78  82  72]\n","  [ 84  84  74]\n","  [ 82  76  82]]\n","\n"," [[128 116 116]\n","  [118 124 128]\n","  [138 130 120]\n","  [126 156 132]]]\n","[[74 79 71]\n"," [78 82 72]\n"," [84 84 74]\n"," [82 76 82]]\n","[[ 84  84  74]\n"," [138 130 120]]\n"]}],"source":["T_reshaped = T.transpose(2,0,1)\n","print(T_reshaped)\n","print(T_reshaped[0])\n","print(T_reshaped[:, 2, :])"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[ 74 128]\n","  [ 78 118]\n","  [ 84 138]\n","  [ 82 126]]\n","\n"," [[ 79 116]\n","  [ 82 124]\n","  [ 84 130]\n","  [ 76 156]]\n","\n"," [[ 71 116]\n","  [ 72 128]\n","  [ 74 120]\n","  [ 82 132]]]\n","[[ 74 128]\n"," [ 78 118]\n"," [ 84 138]\n"," [ 82 126]]\n","[[128 118 138 126]\n"," [116 124 130 156]\n"," [116 128 120 132]]\n"]}],"source":["T_reshaped=T.transpose(1,0,2)\n","print(T_reshaped)\n","print(T_reshaped[0])\n","print(T_reshaped[:, :, 1])"]},{"cell_type":"markdown","metadata":{"id":"uHO2Xul2NSuv"},"source":["---\n","\n","Tensor-vector product is simply a sequence of matrix-vector products which in turn are a sequence of dot products of vectors\n","\n","---"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"z8KWeNkQNU-r"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[ 74 128]\n","  [ 79 116]\n","  [ 71 116]]\n","\n"," [[ 78 118]\n","  [ 82 124]\n","  [ 72 128]]\n","\n"," [[ 84 138]\n","  [ 84 130]\n","  [ 74 120]]\n","\n"," [[ 82 126]\n","  [ 76 156]\n","  [ 82 132]]]\n","[1 0]\n","(4, 3, 2)\n","(2,)\n","[[74 79 71]\n"," [78 82 72]\n"," [84 84 74]\n"," [82 76 82]]\n"]}],"source":["x = np.array([1, 0])\n","print(T)\n","print(x)\n","print(T.shape)\n","print(x.shape)\n","print(np.dot(T, x))"]},{"cell_type":"markdown","metadata":{"id":"SbT0b228VGgR"},"source":["---\n","\n","Linear combination of columns of the matrix using the components of the vector is equivalent to the dot product of the rows of the matrix with the vector\n","\n","----"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"3p0zwE06VJJ2"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[ 1  2 -1 -1]\n"," [ 2  4 -2  3]\n"," [-1  1 -2  4]]\n","[-1  1  1  0]\n","[0 0 0]\n","[0 0 0]\n"]},{"data":{"text/plain":["array([0, 0, 0])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["print(A)\n","print(x)\n","# Dot product of rows of A with x\n","print(np.dot(A, x))\n","# Linear combination of columns of A using components of x\n","print(x[0]*A[:, 0] + x[1]*A[:, 1] + x[2]*A[:, 2] + x[3]*A[:, 3])\n","np.sum(x[range(4)] * A[:, range(4)], axis = 1) # faster"]},{"cell_type":"markdown","metadata":{},"source":["Matrix-Matrix product"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1 2 3]\n"," [4 5 6]]\n","[[ 7 10]\n"," [ 8 11]\n"," [ 9 12]]\n","[[ 50  68]\n"," [122 167]]\n"]}],"source":["A=np.array([[1,2,3],[4,5,6]])\n","B=np.array([[7,10],[8,11],[9,12]])\n","print(A)\n","print(B)\n","print(np.dot(A, B))"]},{"cell_type":"markdown","metadata":{},"source":["Tensor-matrix"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(4, 3, 2)\n","(2, 2)\n"]},{"data":{"text/plain":["array([[[128, 202],\n","        [116, 195],\n","        [116, 187]],\n","\n","       [[118, 196],\n","        [124, 206],\n","        [128, 200]],\n","\n","       [[138, 222],\n","        [130, 214],\n","        [120, 194]],\n","\n","       [[126, 208],\n","        [156, 232],\n","        [132, 214]]])"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["T = np.array([[[74, 128], [79, 116], [71, 116]],\n","              [[78, 118], [82, 124], [72, 128]],\n","              [[84, 138], [84, 130], [74, 120]],\n","              [[82, 126], [76, 156], [82, 132]]])\n","X=np.array([[0,1],[1,1]])\n","print(T.shape)\n","print(X.shape)\n","np.dot(T,X)"]},{"cell_type":"markdown","metadata":{"id":"kL3GsXioG9YZ"},"source":["\n","\n","---\n","\n","\n","The $\\texttt{sympy}$ library in Python is for symbolic computing. When using this library, everything including numbers are treated as symbols. This library can be used for calculating the RREF of an augmented matrix coming from a system of linear equations. Consider the system of linear equations $$\\boxed{\\begin{align*}x_1+2x_2-x_3-x_4&={\\color{cyan}1},\\\\2x_1+4x_2-2x_3+3x_4&={\\color{cyan}3},\\\\-x_1+x_2-2x_3+4x_4&={\\color{cyan}2}.\\end{align*}}$$\n","Note the folowing equivalent ways of interpreting this system of equations:\n","$$\\boxed{\\begin{align*}\\underbrace{\\begin{bmatrix}\n","1 &2 & -1 & -1  \\\\\n","2 & 4 & -2 & 3  \\\\\n","-1 & 1 & -2 & 4   \n","\\end{bmatrix}}_{A}\\underbrace{\\begin{bmatrix}x_1\\\\x_2\\\\x_3\\\\x_4\\end{bmatrix}}_{x}&=\\underbrace{\\begin{bmatrix}{\\color{cyan}1}\\\\{\\color{cyan}3}\\\\{\\color{cyan}2}\\end{bmatrix}}_{\\color{cyan}b}\\end{align*}}\\Longleftrightarrow \\underbrace{\\boxed{x_1a_1+x_2a_2+x_3a_3+x_4a_4 = {\\color{cyan}b}}}_{\\color{green}{\\text{linear combination of columns of }A}}\\Longleftrightarrow \\underbrace{\\boxed{\\begin{bmatrix}a^{(1)}\\cdot x\\\\a^{(2)}\\cdot x\\\\a^{(3)}\\cdot x\\end{bmatrix} =\\begin{bmatrix}{\\color{cyan}1}\\\\{\\color{cyan}3}\\\\{\\color{cyan}2}\\end{bmatrix}}.}_{\\color{green}{\\text{Dot product of }x\\text{ with rows of }A}}$$ The augmented matrix for this system of equations is $$\\begin{align*}\n","\\begin{bmatrix}\n","1 &2 & -1 & -1 &\\lvert& {\\color{cyan}1}\\\\\n","2 & 4 & -2 & 3 & \\lvert&{\\color{cyan}3}\\\\\n","-1 & 1 & -2 & 4 & \\lvert&{\\color{cyan}2}\n","\\end{bmatrix}.\n","\\end{align*}$$\n","The RREF of this augmented matrix can be calculated using the following Python code:\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kzNJmnvI7zAG"},"outputs":[],"source":["# Augmented matrix\n","Ag = sp.Matrix([[1,2,-1,-1,0], [2,4,-2,3,0], [-1,1,-2,4,0]])\n","\n","# Return the RREF and the pivot column indices as a tuple\n","print(Ag.rref())"]},{"cell_type":"markdown","metadata":{"id":"lsL87FkOMr2r"},"source":["---\n","\n","This shows that $x_1, x_2,$ and $x_4$ are pivot variables and that $x_3$ is the only free variable. This system is $\\color{green}{consistent}$ with $\\color{green}{infinitely\\ many\\ solutions}$ as we see from the RREF above that\n","$$x_1=-x_3-(2/5),\\,x_2=x_3+(4/5),\\,x_4=1/5,$$\n","where $x_3$ can be any (real) number. We can also express the solution in vector notation as follows:\n","\\begin{align*}\n","x &= \\begin{bmatrix}x_1\\\\x_2\\\\x_3\\\\x_4\\end{bmatrix} = \\begin{bmatrix}-x_3-\\frac{2}{5}\\\\x_3+\\frac{4}{5}\\\\x_3\\\\\\frac{1}{5}\\end{bmatrix} = \\underbrace{x_3\\begin{bmatrix}-1\\\\1\\\\1\\\\0\\end{bmatrix}}_{\\text{solution to }Ax=0}+\\underbrace{\\begin{bmatrix}-\\frac{2}{5}\\\\\\frac{4}{5}\\\\0\\\\\\frac{1}{5}\\end{bmatrix}}_{\\text{particular solution}},\n","\\end{align*}  \n","noting again that $x_3$ can be any (real) number. Note that the solution has two parts:\n","\n","* the first one involving the free variable(s) is the solutions to $Ax = 0$ (called the null space solution);\n","* the next one is the particular solution to $Ax=b.$\n","\n","\n","\n","\n","---"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
